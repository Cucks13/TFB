{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este cuaderno, desarrollaremos un frontend de Streamlit para un asistente chatbot impulsado por OpenAI. Este chatbot podrá conversar sobre todos los productos almacenados en una base de datos MongoDB. Cubriremos la configuración de la aplicación Streamlit, la integración con la API de OpenAI y la conexión a la base de datos MongoDB para obtener información sobre los productos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-27 11:13:59.585 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-27 11:13:59.586 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-27 11:13:59.586 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-27 11:13:59.587 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-27 11:13:59.587 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-27 11:13:59.588 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-27 11:13:59.915 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-27 11:13:59.916 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-27 11:13:59.917 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-27 11:13:59.918 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-27 11:13:59.919 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-27 11:13:59.920 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-27 11:13:59.921 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-27 11:13:59.921 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-27 11:13:59.922 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-27 11:13:59.922 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-27 11:13:59.923 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-27 11:13:59.924 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-27 11:13:59.925 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-27 11:13:59.925 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-27 11:13:59.926 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import dotenv\n",
    "from openai import OpenAI  # type: ignore\n",
    "\n",
    "# Cargar variables de entorno desde .env\n",
    "dotenv.load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Verificar si la clave está configurada\n",
    "if not api_key:\n",
    "    st.error(\"No se encontró la clave de API en el archivo .env. Verifica la configuración.\")\n",
    "    st.stop()\n",
    "\n",
    "# Configurar cliente OpenAI\n",
    "cliente = OpenAI(api_key=api_key)\n",
    "\n",
    "# ID del asistente (Especificado manualmente)\n",
    "assistant_id = \"asst_SOmHiZ04bWxZcFsQKpIxe1CE\"\n",
    "\n",
    "# Título de la aplicación\n",
    "st.title(\"Asistente AI con OpenAI Assistants\")\n",
    "st.write(f\"Asistente seleccionado: {assistant_id}\")\n",
    "\n",
    "# Crear hilo\n",
    "try:\n",
    "    hilo = cliente.beta.threads.create()\n",
    "    thread_id = hilo.id\n",
    "    st.write(\"Se creó un hilo para esta conversación.\")\n",
    "except Exception as e:\n",
    "    st.error(f\"Error al crear el hilo: {e}\")\n",
    "    st.stop()\n",
    "\n",
    "# Input del usuario\n",
    "mensaje = st.text_area(\"Escribe tu mensaje para el asistente:\")\n",
    "\n",
    "# Botón para enviar mensaje\n",
    "if st.button(\"Enviar mensaje\"):\n",
    "    if mensaje.strip() == \"\":\n",
    "        st.warning(\"Por favor, escribe un mensaje antes de enviarlo.\")\n",
    "    else:\n",
    "        st.write(\"Procesando tu mensaje...\")\n",
    "\n",
    "        # Función para procesar datos\n",
    "        def process_data(openai_client, assistant_id, thread_id, message):\n",
    "            try:\n",
    "                # Enviar el mensaje al asistente\n",
    "                openai_client.beta.threads.messages.create(\n",
    "                    thread_id=thread_id,\n",
    "                    role=\"user\",\n",
    "                    content=message,\n",
    "                )\n",
    "\n",
    "                # Ejecutar el hilo con el asistente\n",
    "                run = openai_client.beta.threads.runs.create(\n",
    "                    thread_id=thread_id,\n",
    "                    assistant_id=assistant_id\n",
    "                )\n",
    "\n",
    "                # Esperar a que se complete la ejecución\n",
    "                while True:\n",
    "                    run_status = openai_client.beta.threads.runs.retrieve(\n",
    "                        thread_id=thread_id,\n",
    "                        run_id=run.id\n",
    "                    )\n",
    "                    if run_status.status == \"completed\":\n",
    "                        st.success(\"Se completó exitosamente.\")\n",
    "                        break\n",
    "                    elif run_status.status == \"failed\":\n",
    "                        st.error(\"Falló.\")\n",
    "                        break\n",
    "                    else:\n",
    "                        st.write(\"Esperando a que se complete...\")\n",
    "                        time.sleep(2)\n",
    "\n",
    "                # Obtener respuestas del asistente\n",
    "                response_messages = openai_client.beta.threads.messages.list(thread_id=thread_id)\n",
    "\n",
    "                assistant_response = None\n",
    "                for message in response_messages.data:\n",
    "                    if message.role == \"assistant\":\n",
    "                        assistant_response = \"\\n\".join([block.text.value for block in message.content])\n",
    "                        break\n",
    "\n",
    "                if assistant_response:\n",
    "                    return assistant_response\n",
    "                else:\n",
    "                    return \"No se encontró una respuesta del asistente.\"\n",
    "\n",
    "            except Exception as e:\n",
    "                st.error(f\"Error al procesar los datos: {e}\")\n",
    "                return None\n",
    "\n",
    "        # Procesar el mensaje\n",
    "        respuesta = process_data(cliente, assistant_id, thread_id, mensaje)\n",
    "\n",
    "        # Mostrar la respuesta\n",
    "        if respuesta:\n",
    "            st.write(\"### Respuesta del asistente:\")\n",
    "            st.write(respuesta)\n",
    "        else:\n",
    "            st.error(\"No se pudo obtener una respuesta del asistente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones\n",
    "import pandas as pd # type: ignore\n",
    "import time\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import os\n",
    "import dotenv # type: ignore\n",
    "dotenv.load_dotenv()\n",
    "from openai import OpenAI # type: ignore\n",
    "\n",
    "\n",
    "os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "cliente = OpenAI()\n",
    "\n",
    "\n",
    "lista_asistentes = cliente.beta.assistants.list(\n",
    "        order=\"desc\",\n",
    "        limit=\"20\",\n",
    "    )\n",
    "print(lista_asistentes)\n",
    "\n",
    "asistente = cliente.beta.assistants.retrieve(\n",
    "        assistant_id=\"asst_OtCItloxVZqVFDoiWt5PFYez\"\n",
    "    )\n",
    "hilo = cliente.beta.threads.create()\n",
    "\n",
    "\n",
    "def process_data(openai_client, assistant_id, thread_id, message):\n",
    "\n",
    "    openai_client.beta.threads.messages.create(\n",
    "        thread_id=thread_id,\n",
    "        role=\"user\",\n",
    "        content=message,\n",
    "    )\n",
    "\n",
    "    run = openai_client.beta.threads.runs.create(\n",
    "        thread_id=thread_id,\n",
    "        assistant_id=assistant_id\n",
    "    )\n",
    "\n",
    "    run_status = openai_client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread_id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "        run_status = openai_client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread_id,\n",
    "            run_id=run.id\n",
    "        )\n",
    "        if run_status.status == \"completed\":\n",
    "            print(\"se completó exitosamente.\")\n",
    "            break\n",
    "        elif run_status.status == \"failed\":\n",
    "            print(\"falló.\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Esperando a que se complete...\")\n",
    "            time.sleep(2)\n",
    "\n",
    "    print(f\"Thread ID: {thread_id}\")\n",
    "    print(f\"Run ID: {run.id}\")\n",
    "    print(f\"Run Status: {run_status.status}\")\n",
    "\n",
    "    response_messages = openai_client.beta.threads.messages.list(thread_id=thread_id)\n",
    "\n",
    "    assistant_response = None\n",
    "    for message in response_messages.data:\n",
    "        if message.role == \"assistant\":\n",
    "            assistant_response = \"\\n\".join([block.text.value for block in message.content])\n",
    "            print(message.content)\n",
    "            break\n",
    "\n",
    "    if assistant_response:\n",
    "        print(f\"Respuesta del asistente:\\n{assistant_response}\")\n",
    "    else:\n",
    "        print(\"No se encontró una respuesta del asistente.\")\n",
    "\n",
    "    return assistant_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = process_data(cliente, asistente.id, hilo.id, \"Hola, me puedes hacer una query que me traiga los datos de dentro de las colecciones\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
